{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torchvision.datasets import MNIST\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(target, pred):\n",
    "    return metrics.accuracy_score(target.detach().cpu().numpy(), pred.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_trainset = MNIST(\"../\", train=True, download=False)\n",
    "letter_testset  = MNIST(\"../\", train=False, download=False)\n",
    "letter_trainset.data[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: torch.Size([1800, 28, 28])\n",
      "Test : torch.Size([600, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "n_train_data = 600\n",
    "n_testn_data = 200\n",
    "\n",
    "# Train\n",
    "train_to = letter_trainset.data[letter_trainset.targets == 15][:n_train_data].float()/255\n",
    "train_tx = letter_trainset.data[letter_trainset.targets == 24][:n_train_data].float()/255\n",
    "\n",
    "train_lo = letter_trainset.targets[letter_trainset.targets == 15][:n_train_data]\n",
    "train_lx = letter_trainset.targets[letter_trainset.targets == 24][:n_train_data]\n",
    "train_lo[:] = 1\n",
    "train_lx[:] = 2\n",
    "\n",
    "# train_t_ = torch.zeros_like(train_to)\n",
    "train_t_ = torch.randint_like(train_to, low=0, high=20)/255\n",
    "train_l_ = torch.zeros_like(train_lo)\n",
    "\n",
    "\n",
    "x_train = (torch.cat((train_to,train_tx,train_t_)) > 0.1) * 1.0\n",
    "y_train = torch.cat((train_lo,train_lx,train_l_))\n",
    "\n",
    "# test\n",
    "test_to = letter_testset.data[letter_testset.targets == 15][n_train_data:n_train_data+n_testn_data].float()/255\n",
    "test_tx = letter_testset.data[letter_testset.targets == 24][n_train_data:n_train_data+n_testn_data].float()/255\n",
    "\n",
    "test_lo = letter_testset.targets[letter_testset.targets == 15][n_train_data:n_train_data+n_testn_data]\n",
    "test_lx = letter_testset.targets[letter_testset.targets == 24][n_train_data:n_train_data+n_testn_data]\n",
    "test_lo[:] = 1\n",
    "test_lx[:] = 2\n",
    "\n",
    "# test_t_ = torch.zeros_like(test_to)\n",
    "test_t_ = torch.randint_like(test_to, low=0, high=20)/255\n",
    "test_l_ = torch.zeros_like(test_lo)\n",
    "\n",
    "x_test = (torch.cat((test_to,test_tx,test_t_)) > 0.1) * 1.0\n",
    "y_test = torch.cat((test_lo,test_lx,test_l_))\n",
    "\n",
    "print(\"Train:\",x_train.shape)\n",
    "print(\"Test :\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(x_train, y_train)\n",
    "test_set  = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=64, drop_last=True)\n",
    "test_loader  = DataLoader(test_set, shuffle=True, batch_size=64, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a few MNIST examples\n",
    "idx, dim, classes = 0, 28, 10\n",
    "# create empty canvas\n",
    "canvas = np.zeros((dim*classes, classes*dim))\n",
    "\n",
    "# fill with tensors\n",
    "for i in range(classes):\n",
    "    for j in range(classes):\n",
    "        canvas[i*dim:(i+1)*dim, j*dim:(j+1)*dim] = x_train[idx].reshape((dim, dim))\n",
    "        idx = np.random.randint(0, n_train_data*3)\n",
    "\n",
    "# visualize matrix of tensors as gray scale image\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.axis('off')\n",
    "plt.imshow(canvas, cmap='gray')\n",
    "plt.title('Letters handwritten digits')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Model(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (batchN1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchN2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=800, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=3, bias=True)\n",
      "  (log): LogSoftmax(dim=1)\n",
      "  (Lrelu): LeakyReLU(negative_slope=0.01)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "num_classes = 3\n",
    "num_features = x_train.shape[1]\n",
    "\n",
    "# define network\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # Your code here!\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.batchN1 = nn.BatchNorm2d(16)\n",
    "        self.batchN2 = nn.BatchNorm2d(32)\n",
    "        self.drop    = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "        self.fc1   = nn.Linear(800, 256)\n",
    "        self.fc2   = nn.Linear(256, 128)\n",
    "        self.fc3   = nn.Linear(128, self.num_classes)\n",
    "        self.log   = nn.LogSoftmax(dim=1)\n",
    "        self.Lrelu = nn.LeakyReLU()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Your code here!\n",
    "        x = x.view(64,1,28,28)\n",
    "        x = self.drop(self.batchN1(self.pool(self.Lrelu(self.conv1(x)))))\n",
    "        x = self.drop(self.batchN2(self.pool(self.Lrelu(self.conv2(x)))))\n",
    "        x = self.flat(x)\n",
    "        x = self.Lrelu(self.fc1(x))\n",
    "        x = self.Lrelu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.log(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Model(num_classes)\n",
    "# use cuda or cpu\n",
    "if torch.cuda.is_available(): device = torch.device('cuda')  \n",
    "else:                         device = torch.device('cpu')\n",
    "model.load_state_dict(torch.load('model.pth', weights_only=False))\n",
    "model.to(device)\n",
    "print(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the training loop\n",
    "\n",
    "We train the network by calculating the gradient w.r.t the cost function and update the parameters in direction of the negative gradient. \n",
    "\n",
    "\n",
    "When training neural network you always use mini batches. Instead of calculating the average gradient using the entire dataset you approximate the gradient using a mini-batch of typically 16 to 256 samples. The paramters are updated after each mini batch. Networks converge much faster using mini batches because the parameters are updated more often.\n",
    "\n",
    "We build a loop that iterates over the training data. Remember that the parameters are updated each time ``optimizer.step()`` is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855d8e2606614fb7bed71ccca43aff36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "validation_every_steps = 25\n",
    "\n",
    "step = 0\n",
    "model.train()\n",
    "\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "        \n",
    "for epoch in (pbar:=tqdm(range(num_epochs))):\n",
    "    \n",
    "    train_accuracies_batches = []\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass, compute gradients, perform one training step.\n",
    "        # Your code here!\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        train_loss = loss_fn(output, targets)\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Increment step counter\n",
    "        step += 1\n",
    "        \n",
    "        # Compute accuracy.\n",
    "        predictions = output.max(1)[1]\n",
    "        train_accuracies_batches.append(accuracy(targets, predictions))\n",
    "        \n",
    "        if step % validation_every_steps == 0:\n",
    "            \n",
    "            # Append average training accuracy to list.\n",
    "            train_accuracies.append(np.mean(train_accuracies_batches))\n",
    "            \n",
    "            train_accuracies_batches = []\n",
    "        \n",
    "            # Compute accuracies on validation set.\n",
    "            valid_accuracies_batches = []\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for inputs, targets in test_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    output = model(inputs)\n",
    "                    loss = loss_fn(output, targets)\n",
    "\n",
    "                    predictions = output.max(1)[1]\n",
    "\n",
    "                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).\n",
    "                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))\n",
    "\n",
    "                model.train()\n",
    "                \n",
    "            # Append average validation accuracy to list.\n",
    "            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))\n",
    "     \n",
    "            # print(f\"Step {step:<5}   training accuracy: {train_accuracies[-1]}\")\n",
    "            # print(f\"                 test accuracy: {valid_accuracies[-1]}\")\n",
    "            pbar.set_description(f\"Step {step:<5}   training accuracy: {train_accuracies[-1]:.3f}   test accuracy: {valid_accuracies[-1]:.3f}\")\n",
    "\n",
    "print(\"Finished training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.9465e+00, -6.6356e+00, -3.9355e-03],\n",
      "        [-8.9979e+00, -5.3677e-04, -7.7920e+00],\n",
      "        [-8.1045e+00, -9.7180e+00, -3.6245e-04],\n",
      "        [-6.6055e+00, -3.5776e-03, -6.1110e+00],\n",
      "        [-5.6548e+00, -7.7762e-03, -5.4620e+00],\n",
      "        [-9.6575e+00, -2.7557e-04, -8.4608e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.7847e+00, -2.3493e-04, -8.6304e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.2324e+00, -7.6203e+00, -1.2140e-03],\n",
      "        [-8.4578e+00, -9.5870e+00, -2.8094e-04],\n",
      "        [-6.9238e+00, -6.8924e+00, -2.0015e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-4.2400e+00, -4.2358e-02, -3.6095e+00],\n",
      "        [-6.5507e+00, -7.4926e+00, -1.9883e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.2555e+00, -3.0602e-03, -6.0537e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.1769e+00, -2.6756e-03, -6.2617e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.9274e+00, -1.6185e-03, -6.6794e+00],\n",
      "        [-1.0034e+01, -2.2373e-04, -8.6234e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.1633e+00, -6.0533e+00, -4.4654e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.0192e+01, -1.5699e-04, -9.0322e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.4098e+00, -3.6316e-04, -8.1763e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.7542e+00, -5.6968e+00, -6.5475e-03],\n",
      "        [-7.3516e+00, -8.3461e+00, -8.7926e-04],\n",
      "        [-6.6061e+00, -6.6192e-03, -5.2504e+00],\n",
      "        [-9.5042e+00, -1.0752e+01, -9.5959e-05],\n",
      "        [-7.9372e+00, -1.2031e-03, -7.0760e+00],\n",
      "        [-5.9069e+00, -7.4478e+00, -3.3087e-03],\n",
      "        [-7.5597e+00, -8.7019e+00, -6.8760e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-4.0643e+00, -4.8439e+00, -2.5371e-02],\n",
      "        [-6.1411e+00, -4.3651e-03, -6.1179e+00],\n",
      "        [-7.3119e+00, -8.8805e+00, -8.0696e-04],\n",
      "        [-5.2281e+00, -1.5468e-02, -4.6067e+00],\n",
      "        [-7.0697e+00, -3.8699e-03, -5.8052e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.2100e+00, -1.0683e+01, -1.2290e-04],\n",
      "        [-8.4853e+00, -9.4375e+00, -2.8630e-04],\n",
      "        [-6.0917e+00, -6.7404e+00, -3.4498e-03],\n",
      "        [-7.9620e+00, -8.6049e+00, -5.3177e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.9227e+00, -4.8113e-04, -7.9641e+00],\n",
      "        [-5.0995e+00, -1.3457e-02, -4.9244e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00]], device='cuda:0')\n",
      "tensor([[-3.3140e+00, -5.0170e+00, -4.3946e-02],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.6127e+00, -8.8245e+00, -6.4150e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.2260e+00, -1.0118e+01, -3.0799e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.1700e+00, -4.3609e+00, -1.8624e-02],\n",
      "        [-7.3356e+00, -2.1405e-03, -6.5115e+00],\n",
      "        [-5.7819e+00, -6.6578e+00, -4.3765e-03],\n",
      "        [-7.8882e+00, -1.0921e-03, -7.2414e+00],\n",
      "        [-9.0367e-01, -1.0981e+00, -1.3417e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.0004e+01, -1.8809e-04, -8.8536e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.7127e+00, -2.0778e-03, -6.4201e+00],\n",
      "        [-7.9194e+00, -1.4345e-03, -6.8402e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.5107e+00, -8.1093e+00, -1.7898e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-3.8549e+00, -4.0896e+00, -3.8660e-02],\n",
      "        [-6.8445e+00, -5.5336e-03, -5.4142e+00],\n",
      "        [-5.8368e+00, -6.6338e+00, -4.2422e-03],\n",
      "        [-6.2107e+00, -7.3849e+00, -2.6318e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.9244e+00, -5.2450e-04, -7.8460e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-4.8484e+00, -6.0678e+00, -1.0209e-02],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.1625e+00, -2.7028e-03, -6.2534e+00],\n",
      "        [-9.2011e+00, -3.5113e-04, -8.2934e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.0591e+00, -4.9698e-04, -7.8739e+00],\n",
      "        [-8.5934e+00, -7.9076e-04, -7.4101e+00],\n",
      "        [-2.6997e+00, -4.1879e+00, -8.5998e-02],\n",
      "        [-6.0798e+00, -7.7622e+00, -2.7179e-03],\n",
      "        [-6.4353e+00, -5.9519e-03, -5.4421e+00],\n",
      "        [-6.9512e+00, -7.9124e+00, -1.3246e-03],\n",
      "        [-7.7448e+00, -1.2688e-03, -7.0880e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.4120e+00, -8.1384e+00, -8.9653e-04],\n",
      "        [-5.8923e+00, -6.2206e+00, -4.7601e-03],\n",
      "        [-8.7618e+00, -6.5830e-04, -7.5979e+00],\n",
      "        [-8.1110e+00, -9.1094e-04, -7.4016e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.1112e+00, -8.3699e+00, -2.4526e-03],\n",
      "        [-6.6203e+00, -7.8604e+00, -1.7201e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.5512e+00, -6.6988e+00, -5.1281e-03],\n",
      "        [-5.0913e+00, -1.5017e-02, -4.7382e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-2.0864e+00, -4.1417e+00, -1.5086e-01],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.0661e+00, -4.4836e-04, -8.0080e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.2060e+00, -1.3108e-03, -6.8714e+00],\n",
      "        [-6.5414e+00, -3.1109e-03, -6.3988e+00],\n",
      "        [-5.5818e+00, -7.2083e+00, -4.5164e-03],\n",
      "        [-8.7748e+00, -7.9552e-04, -7.3530e+00]], device='cuda:0')\n",
      "tensor([[-7.6792e+00, -1.3132e-03, -7.0703e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.9698e+00, -1.0082e+01, -1.6902e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.6732e+00, -7.7810e+00, -1.6834e-03],\n",
      "        [-8.5963e+00, -6.5996e-04, -7.6524e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.3334e+00, -8.2964e+00, -9.0320e-04],\n",
      "        [-9.2318e+00, -4.5563e-04, -7.9360e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.8137e+00, -2.0346e-02, -4.0655e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.8973e+00, -6.2422e-04, -7.6266e+00],\n",
      "        [-8.9012e+00, -5.4309e-04, -7.8073e+00],\n",
      "        [-9.6639e+00, -2.5770e-04, -8.5469e+00],\n",
      "        [-6.5826e+00, -3.6878e-03, -6.0762e+00],\n",
      "        [-3.7525e+00, -4.7699e+00, -3.2462e-02],\n",
      "        [-9.2932e+00, -4.4491e-04, -7.9496e+00],\n",
      "        [-8.3634e+00, -8.2923e-04, -7.4260e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.2756e+00, -8.2911e-04, -7.4626e+00],\n",
      "        [-7.6716e+00, -8.7676e+00, -6.2172e-04],\n",
      "        [-6.0240e+00, -5.6306e+00, -6.0244e-03],\n",
      "        [-6.8758e+00, -8.3672e+00, -1.2657e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.1544e+00, -5.6120e+00, -9.4727e-03],\n",
      "        [-9.2888e+00, -3.2038e-04, -8.3868e+00],\n",
      "        [-6.0063e+00, -8.3152e-03, -5.1469e+00],\n",
      "        [-9.6163e+00, -2.6199e-04, -8.5410e+00],\n",
      "        [-7.5074e+00, -8.8418e+00, -6.9380e-04],\n",
      "        [-2.5415e+00, -4.6509e+00, -9.2441e-02],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.8724e+00, -1.1326e-03, -7.1943e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.5199e+00, -8.2534e+00, -8.0291e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.3725e+00, -7.0649e+00, -2.5658e-03],\n",
      "        [-5.9851e+00, -6.9389e+00, -3.4914e-03],\n",
      "        [-8.2557e+00, -1.3051e-03, -6.8642e+00],\n",
      "        [-8.2882e+00, -6.6914e-04, -7.7815e+00],\n",
      "        [-6.1660e+00, -6.2242e-03, -5.4955e+00],\n",
      "        [-8.1544e+00, -9.6402e+00, -3.5256e-04],\n",
      "        [-9.3947e+00, -3.1800e-04, -8.3570e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.8889e+00, -8.5600e+00, -5.6668e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.3526e+00, -7.9830e+00, -2.0855e-03],\n",
      "        [-8.5403e+00, -9.7228e+00, -2.5543e-04],\n",
      "        [-7.0979e+00, -3.2449e-03, -6.0270e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.2282e+00, -1.1613e-02, -5.0860e+00],\n",
      "        [-7.8890e+00, -1.8672e-03, -6.5085e+00],\n",
      "        [-7.4746e+00, -9.0277e+00, -6.8760e-04],\n",
      "        [-4.1059e+00, -4.0853e+00, -3.3860e-02],\n",
      "        [-7.3468e+00, -8.5572e+00, -8.3709e-04],\n",
      "        [-4.7682e+00, -6.7204e+00, -9.7488e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.0481e+00, -1.0971e+01, -1.3482e-04],\n",
      "        [-9.7017e+00, -2.4483e-04, -8.6027e+00]], device='cuda:0')\n",
      "tensor([[-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.8830e+00, -1.0681e+01, -1.6175e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.7525e+00, -3.5661e-03, -6.0357e+00],\n",
      "        [-5.9100e+00, -6.8673e+00, -3.7604e-03],\n",
      "        [-4.1350e+00, -4.7727e-01, -1.0119e+00],\n",
      "        [-7.6786e+00, -8.5019e+00, -6.6592e-04],\n",
      "        [-7.9042e+00, -1.1267e-03, -7.1862e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.6525e+00, -1.0083e+01, -2.1658e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.8194e+00, -1.1288e-03, -7.2276e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.9891e+00, -5.4595e-04, -7.7727e+00],\n",
      "        [-9.1659e+00, -1.1201e+01, -1.1825e-04],\n",
      "        [-7.7064e+00, -1.5128e-03, -6.8479e+00],\n",
      "        [-5.7830e+00, -7.1490e+00, -3.8728e-03],\n",
      "        [-3.6775e+00, -4.9113e+00, -3.3193e-02],\n",
      "        [-8.8999e+00, -5.2784e-04, -7.8461e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.8869e+00, -3.7023e-03, -5.9240e+00],\n",
      "        [-8.9212e+00, -5.0306e-04, -7.9036e+00],\n",
      "        [-3.4649e+00, -4.1888e+00, -4.7553e-02],\n",
      "        [-6.7113e+00, -7.9913e+00, -1.5566e-03],\n",
      "        [-8.5500e+00, -7.4228e-04, -7.5083e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.0731e+00, -1.0000e-03, -7.2822e+00],\n",
      "        [-7.0841e+00, -7.7396e+00, -1.2744e-03],\n",
      "        [-8.1159e+00, -1.0480e-03, -7.1971e+00],\n",
      "        [-9.3967e+00, -3.8092e-04, -8.1191e+00],\n",
      "        [-7.5008e+00, -1.6223e-03, -6.8417e+00],\n",
      "        [-8.4590e+00, -9.6251e-04, -7.1953e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.1411e+00, -9.1054e+00, -4.0249e-04],\n",
      "        [-8.5451e+00, -7.3132e-04, -7.5304e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.4488e+00, -9.8818e+00, -2.6532e-04],\n",
      "        [-8.6864e+00, -7.4776e-04, -7.4548e+00],\n",
      "        [-7.7092e+00, -8.7260e+00, -6.1112e-04],\n",
      "        [-8.4114e+00, -9.9069e+00, -2.7212e-04],\n",
      "        [-5.1129e-01, -2.7193e+00, -1.0956e+00],\n",
      "        [-5.1790e+00, -5.0555e+00, -1.2081e-02],\n",
      "        [-1.0144e+01, -1.7725e-04, -8.8885e+00],\n",
      "        [-5.0641e+00, -5.6587e+00, -9.8547e-03],\n",
      "        [-6.5063e+00, -6.1479e+00, -3.6384e-03],\n",
      "        [-1.0327e+01, -1.2957e-04, -9.2423e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.5283e+00, -1.0459e+01, -2.2659e-04],\n",
      "        [-9.9204e+00, -2.0049e-04, -8.7962e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.4665e+00, -6.6394e+00, -2.8664e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.9081e+00, -6.7536e+00, -3.8915e-03],\n",
      "        [-7.3280e+00, -1.9231e-03, -6.6732e+00],\n",
      "        [-3.9241e+00, -5.1362e+00, -2.5976e-02],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-4.5202e+00, -2.0266e-02, -4.6912e+00],\n",
      "        [-9.0118e+00, -4.1166e-04, -8.1471e+00]], device='cuda:0')\n",
      "tensor([[-6.4401e+00, -6.2025e-03, -5.3845e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.7549e+00, -5.0151e-04, -7.9759e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.3042e+00, -3.9022e-04, -8.1148e+00],\n",
      "        [-9.0681e+00, -3.6722e-04, -8.2869e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.5741e+00, -2.8868e-04, -8.4260e+00],\n",
      "        [-8.5724e+00, -6.7557e-04, -7.6291e+00],\n",
      "        [-6.6178e+00, -6.6428e+00, -2.6431e-03],\n",
      "        [-6.8242e+00, -8.9556e+00, -1.2170e-03],\n",
      "        [-8.5305e+00, -9.9265e+00, -2.4626e-04],\n",
      "        [-5.7162e-01, -1.7080e+00, -1.3698e+00],\n",
      "        [-8.1596e+00, -9.5203e-04, -7.3148e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.5735e+00, -1.0011e-02, -5.0890e+00],\n",
      "        [-9.5668e+00, -2.7998e-04, -8.4686e+00],\n",
      "        [-7.9836e+00, -8.5809e+00, -5.2879e-04],\n",
      "        [-9.2464e+00, -3.8783e-04, -8.1413e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.8866e+00, -1.5572e-03, -6.7421e+00],\n",
      "        [-9.0059e+00, -5.2403e-04, -7.8211e+00],\n",
      "        [-4.9651e+00, -5.9022e+00, -9.7580e-03],\n",
      "        [-5.1311e+00, -6.6973e+00, -7.1698e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.7092e+00, -8.1593e+00, -1.5069e-03],\n",
      "        [-5.7003e+00, -9.1533e-03, -5.1557e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-2.4736e+00, -1.4139e-01, -3.0456e+00],\n",
      "        [-1.4097e+00, -1.6857e+00, -5.6130e-01],\n",
      "        [-7.4951e+00, -9.2880e+00, -6.4865e-04],\n",
      "        [-7.9931e+00, -1.1978e-03, -7.0594e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.3873e+00, -6.6609e+00, -5.8715e-03],\n",
      "        [-5.3488e+00, -5.5144e+00, -8.8211e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.6637e+00, -3.7859e-03, -5.9905e+00],\n",
      "        [-9.1254e+00, -3.6686e-04, -8.2627e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.5549e+00, -8.8171e+00, -6.7200e-04],\n",
      "        [-7.3227e+00, -2.3137e-03, -6.4066e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.0405e+00, -2.1944e-03, -6.6329e+00],\n",
      "        [-8.4629e+00, -1.0007e+01, -2.5627e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.3005e+00, -9.0403e-04, -7.3305e+00],\n",
      "        [-3.7097e+00, -4.8996e+00, -3.2454e-02],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.6210e+00, -5.5037e+00, -7.7224e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.7801e-01, -2.5738e+00, -8.7675e-01],\n",
      "        [-6.6001e+00, -7.1653e+00, -2.1355e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.9258e+00, -8.8575e+00, -5.0365e-04],\n",
      "        [-8.8537e+00, -6.1529e-04, -7.6579e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.5767e+00, -7.5433e+00, -4.3241e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-2.2029e+00, -4.7955e-01, -1.3077e+00],\n",
      "        [-7.1191e+00, -2.6836e-03, -6.2815e+00]], device='cuda:0')\n",
      "tensor([[-8.6307e+00, -6.0504e-04, -7.7604e+00],\n",
      "        [-7.8025e+00, -8.5007e+00, -6.1231e-04],\n",
      "        [-9.8801e+00, -2.0121e-04, -8.8045e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-4.7076e+00, -5.5306e+00, -1.3075e-02],\n",
      "        [-6.4095e+00, -6.9161e+00, -2.6410e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.4056e+00, -8.2900e-04, -7.4102e+00],\n",
      "        [-9.2914e+00, -3.3027e-04, -8.3433e+00],\n",
      "        [-3.6613e+00, -4.2593e+00, -4.0646e-02],\n",
      "        [-7.4092e+00, -1.9594e-03, -6.6062e+00],\n",
      "        [-5.0365e+00, -5.3325e+00, -1.1393e-02],\n",
      "        [-3.8592e+00, -5.6031e+00, -2.5082e-02],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.0226e+00, -5.6793e-03, -5.7322e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.8823e+00, -1.1975e-03, -7.1070e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.9329e+00, -9.3698e+00, -4.4419e-04],\n",
      "        [-6.9631e+00, -2.4389e-03, -6.5091e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.7934e+00, -2.8655e-03, -6.3537e+00],\n",
      "        [-1.0509e+01, -1.2099e-04, -9.2756e+00],\n",
      "        [-6.4095e+00, -4.2092e-03, -5.9698e+00],\n",
      "        [-9.4283e+00, -3.5756e-04, -8.1913e+00],\n",
      "        [-6.4260e+00, -5.5154e+00, -5.6590e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.0601e+01, -1.0240e-04, -9.4654e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.5377e+00, -3.6168e-03, -6.1365e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.8802e+00, -7.8244e+00, -1.4288e-03],\n",
      "        [-2.3372e+00, -4.1584e+00, -1.1904e-01],\n",
      "        [-7.9623e+00, -1.1257e-03, -7.1606e+00],\n",
      "        [-7.1490e+00, -2.0055e-03, -6.7107e+00],\n",
      "        [-3.7128e+00, -3.1664e+00, -6.8883e-02],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.6399e+00, -7.6462e+00, -1.7867e-03],\n",
      "        [-8.5367e+00, -7.8040e-04, -7.4456e+00],\n",
      "        [-9.0972e+00, -4.2966e-04, -8.0549e+00],\n",
      "        [-7.3341e+00, -8.1880e+00, -9.3131e-04],\n",
      "        [-7.0505e+00, -7.9812e+00, -1.2096e-03],\n",
      "        [-8.2543e+00, -9.6924e+00, -3.2193e-04],\n",
      "        [-1.0421e+01, -1.2111e-04, -9.3011e+00],\n",
      "        [-4.1980e+00, -5.1644e+00, -2.0960e-02],\n",
      "        [-7.8733e+00, -9.2326e+00, -4.7875e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.2040e+00, -4.0678e-04, -8.0917e+00],\n",
      "        [-6.1136e+00, -6.7760e-03, -5.3947e+00],\n",
      "        [-6.3840e+00, -4.3143e-03, -5.9459e+00],\n",
      "        [-6.7455e+00, -8.3055e+00, -1.4243e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.1457e+00, -7.2684e+00, -2.8440e-03],\n",
      "        [-6.3768e+00, -6.8269e+00, -2.7887e-03],\n",
      "        [-7.6376e+00, -8.0932e+00, -7.8802e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.9878e+00, -2.0859e-04, -8.7242e+00],\n",
      "        [-7.2743e+00, -8.5791e+00, -8.8152e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00]], device='cuda:0')\n",
      "tensor([[-7.4106e+00, -8.9962e+00, -7.2894e-04],\n",
      "        [-8.9453e+00, -5.0997e-04, -7.8765e+00],\n",
      "        [-8.0800e+00, -1.2504e-03, -6.9697e+00],\n",
      "        [-6.1952e+00, -5.1199e-03, -5.7868e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-4.1865e+00, -3.1831e+00, -5.8323e-02],\n",
      "        [-4.2166e+00, -3.6219e-02, -3.8718e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.9695e+00, -3.3684e-03, -6.0229e+00],\n",
      "        [-4.6182e+00, -5.6887e+00, -1.3343e-02],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-4.8621e+00, -1.5918e-02, -4.8211e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.8977e+00, -3.2506e-03, -6.1035e+00],\n",
      "        [-1.0396e+01, -1.1432e-04, -9.3872e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-4.3015e+00, -3.2270e+00, -5.4691e-02],\n",
      "        [-9.5487e+00, -2.7045e-04, -8.5214e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.4422e+00, -6.3078e-04, -7.7874e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.6795e+00, -7.8176e+00, -1.6604e-03],\n",
      "        [-8.9325e+00, -5.2224e-04, -7.8490e+00],\n",
      "        [-1.0486e+01, -1.3458e-04, -9.1460e+00],\n",
      "        [-8.0251e+00, -1.5446e-03, -6.7119e+00],\n",
      "        [-9.5099e+00, -2.5293e-04, -8.6296e+00],\n",
      "        [-7.2092e+00, -7.8625e+00, -1.1252e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-3.7145e+00, -4.5255e-02, -3.9182e+00],\n",
      "        [-8.0107e+00, -9.8163e+00, -3.8652e-04],\n",
      "        [-8.8957e+00, -4.5933e-04, -8.0402e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.6703e+00, -8.6615e+00, -6.3971e-04],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.3243e+00, -6.4873e+00, -6.4151e-03],\n",
      "        [-8.1688e+00, -8.9903e-04, -7.3934e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.9182e+00, -7.6250e-03, -5.3173e+00],\n",
      "        [-9.2176e+00, -3.3516e-04, -8.3526e+00],\n",
      "        [-7.3844e+00, -2.2456e-03, -6.4239e+00],\n",
      "        [-9.4386e+00, -3.3778e-04, -8.2620e+00],\n",
      "        [-6.3303e+00, -7.4968e+00, -2.3390e-03],\n",
      "        [-1.2210e+00, -3.2615e+00, -4.0538e-01],\n",
      "        [-6.9082e+00, -6.6717e+00, -2.2684e-03],\n",
      "        [-6.8835e+00, -3.4765e-03, -6.0133e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-4.8720e+00, -1.9628e-02, -4.4414e+00],\n",
      "        [-4.0703e+00, -5.9299e-01, -8.4338e-01],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.5499e+00, -3.8100e+00, -2.6712e-01],\n",
      "        [-9.2058e+00, -1.0292e+01, -1.3446e-04],\n",
      "        [-2.6396e+00, -4.3191e+00, -8.8503e-02],\n",
      "        [-7.2339e+00, -1.9638e-03, -6.6924e+00],\n",
      "        [-8.2727e+00, -9.5986e+00, -3.2324e-04],\n",
      "        [-3.1808e+00, -1.0925e-01, -2.7815e+00]], device='cuda:0')\n",
      "tensor([[-7.3496e+00, -7.6652e+00, -1.1123e-03],\n",
      "        [-5.2148e+00, -1.6345e-02, -4.5303e+00],\n",
      "        [-9.1947e+00, -1.0925e+01, -1.1956e-04],\n",
      "        [-7.1453e+00, -3.0085e-03, -6.1123e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.6140e+00, -7.6077e+00, -1.8399e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.3867e+00, -4.5781e+00, -1.4963e-02],\n",
      "        [-9.6545e+00, -2.6544e-04, -8.5108e+00],\n",
      "        [-8.1913e+00, -8.8365e+00, -4.2251e-04],\n",
      "        [-7.0647e+00, -8.2291e+00, -1.1221e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.9008e+00, -2.0693e-04, -8.7609e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.0484e+00, -7.7414e+00, -1.3040e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-2.7905e+00, -9.9844e-02, -3.3923e+00],\n",
      "        [-5.8051e+00, -6.6714e+00, -4.2880e-03],\n",
      "        [-6.6115e+00, -8.0077e+00, -1.6792e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.8113e+00, -6.7820e+00, -4.1360e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.5868e+00, -1.0227e+01, -2.2278e-04],\n",
      "        [-5.9768e+00, -7.3182e+00, -3.2054e-03],\n",
      "        [-5.3665e+00, -5.1990e+00, -1.0245e-02],\n",
      "        [-5.0309e+00, -6.5816e+00, -7.9502e-03],\n",
      "        [-8.2578e+00, -1.3238e-03, -6.8461e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.7420e+00, -9.9552e+00, -2.0716e-04],\n",
      "        [-7.3949e+00, -9.4295e+00, -6.9487e-04],\n",
      "        [-8.9229e+00, -1.0562e+01, -1.5913e-04],\n",
      "        [-8.7624e+00, -1.0269e+01, -1.9119e-04],\n",
      "        [-4.9878e+00, -7.1138e+00, -7.6640e-03],\n",
      "        [-3.1285e+00, -3.9444e+00, -6.5227e-02],\n",
      "        [-9.7205e+00, -2.1098e-04, -8.7991e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-4.5139e+00, -5.8248e+00, -1.4007e-02],\n",
      "        [-8.3969e+00, -1.0891e-03, -7.0552e+00],\n",
      "        [-5.1958e+00, -5.9627e+00, -8.1456e-03],\n",
      "        [-9.9969e+00, -1.7022e-04, -8.9903e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-2.5158e+00, -1.3213e-01, -3.1472e+00],\n",
      "        [-4.9870e+00, -5.5040e+00, -1.0956e-02],\n",
      "        [-9.4788e+00, -2.5960e-04, -8.6055e+00],\n",
      "        [-6.0975e+00, -6.0798e+00, -4.5475e-03],\n",
      "        [-7.1228e+00, -2.6707e-03, -6.2869e+00],\n",
      "        [-6.3529e+00, -7.3111e+00, -2.4126e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.5996e+00, -7.5667e+00, -1.8800e-03],\n",
      "        [-5.6851e+00, -5.0739e+00, -9.7011e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.9651e+00, -7.6527e+00, -1.4200e-03],\n",
      "        [-9.0712e+00, -5.7955e-04, -7.6748e+00],\n",
      "        [-6.4712e+00, -7.6896e+00, -2.0069e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.3314e+00, -9.7085e+00, -3.0167e-04],\n",
      "        [-9.7200e+00, -1.1886e+01, -6.6993e-05],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-6.9067e+00, -7.6549e+00, -1.4759e-03],\n",
      "        [-7.5866e+00, -1.9751e-03, -6.5252e+00],\n",
      "        [-6.6883e+00, -3.3233e-03, -6.1790e+00]], device='cuda:0')\n",
      "tensor([[-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-2.9235e+00, -4.3973e+00, -6.8336e-02],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.9828e+00, -4.5671e-04, -8.0132e+00],\n",
      "        [-7.0764e+00, -2.1688e-03, -6.6289e+00],\n",
      "        [-3.9186e+00, -3.8633e-02, -4.0158e+00],\n",
      "        [-7.1482e+00, -8.3775e+00, -1.0167e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.7899e+00, -6.7479e+00, -4.2404e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.1913e+00, -7.8028e+00, -1.1624e-03],\n",
      "        [-8.7326e+00, -6.6830e-04, -7.5873e+00],\n",
      "        [-7.3085e+00, -1.9549e-03, -6.6584e+00],\n",
      "        [-6.8703e+00, -4.1139e-03, -5.7870e+00],\n",
      "        [-5.8842e+00, -7.2315e-03, -5.4211e+00],\n",
      "        [-6.1771e+00, -6.2219e-03, -5.4904e+00],\n",
      "        [-6.2853e+00, -6.8647e+00, -2.9116e-03],\n",
      "        [-7.1467e+00, -1.9166e-03, -6.7879e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.7460e+00, -2.4506e-04, -8.5868e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.1697e+00, -7.9123e+00, -1.1365e-03],\n",
      "        [-7.5221e+00, -9.0040e+00, -6.6413e-04],\n",
      "        [-5.8542e+00, -5.9926e+00, -5.3795e-03],\n",
      "        [-5.4755e+00, -7.5924e+00, -4.7036e-03],\n",
      "        [-1.0378e+01, -1.2862e-04, -9.2356e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-7.4035e+00, -7.7950e+00, -1.0215e-03],\n",
      "        [-6.7865e+00, -8.4585e+00, -1.3420e-03],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.0399e+00, -4.5206e-04, -8.0061e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-9.4013e+00, -3.1264e-04, -8.3774e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-5.5978e+00, -4.7029e+00, -1.2857e-02],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.2876e+00, -9.5948e+00, -3.1967e-04],\n",
      "        [-5.3419e+00, -6.2605e+00, -6.7197e-03],\n",
      "        [-1.0180e+01, -1.7534e-04, -8.8929e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-4.2049e+00, -6.3557e+00, -1.6800e-02],\n",
      "        [-9.0083e+00, -1.0500e+01, -1.4995e-04],\n",
      "        [-1.8444e+00, -2.4112e-01, -2.8800e+00],\n",
      "        [-4.9974e+00, -4.3059e+00, -2.0451e-02],\n",
      "        [-3.5789e+00, -5.1643e-02, -3.7975e+00],\n",
      "        [-6.3607e+00, -7.1774e+00, -2.4949e-03],\n",
      "        [-7.6430e+00, -1.6660e-03, -6.7379e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-8.2789e+00, -9.5965e-04, -7.2568e+00],\n",
      "        [-9.1516e+00, -3.8235e-04, -8.1942e+00],\n",
      "        [-5.8033e+00, -5.7512e+00, -6.2159e-03],\n",
      "        [-6.4912e+00, -5.0925e-03, -5.6372e+00],\n",
      "        [-7.8281e+00, -9.0775e+00, -5.1283e-04],\n",
      "        [-3.7290e+00, -4.2774e-02, -4.0255e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00]], device='cuda:0')\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "valid_accuracies_batches = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        output = model(inputs)\n",
    "        print(output)\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        predictions = output.max(1)[1]\n",
    "\n",
    "        # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).\n",
    "        valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))\n",
    "\n",
    "    model.train()\n",
    "print(np.sum(valid_accuracies_batches) / len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00],\n",
      "        [-1.4328e-04, -9.9562e+00, -9.2525e+00]], device='cuda:0')\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    output = model(torch.zeros_like(inputs))\n",
    "    print(output)\n",
    "\n",
    "    model.train()\n",
    "print(np.sum(valid_accuracies_batches) / len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "capture1 = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, img = capture1.read() # Read an image\n",
    "    cv2.imshow(\"ImageWindow\", img) # Display the image\n",
    "    # if (cv2.waitKey(2) >= 0): # If the user presses a key, exit while loop\n",
    "    #     break\n",
    "    k = cv2.waitKey(33)\n",
    "    if k==27:    # Esc key to stop\n",
    "        break\n",
    "    elif k==-1:  # normally -1 returned,so don't print it\n",
    "        continue\n",
    "    else:\n",
    "        print(k)\n",
    "cv2.destroyAllWindows() # Close window\n",
    "cv2.VideoCapture(0).release() # Release video device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows() # Close window\n",
    "cv2.VideoCapture(0).release() # Release video device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
